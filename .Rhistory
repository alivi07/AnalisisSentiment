restaurant_review <- my_Dataset %>%
select(text = Text, class = liked)
restaurant_review$class <- as.factor(restaurant_review$class)
glimpse(restaurant_review)
# Ambil 1000 baris per class data untuk sample
like_review <- restaurant_review %>%
filter(class == "1") %>%
sample_n(1000)
dislike_review <- restaurant_review %>%
filter(class == "0") %>%
sample_n(1000)
restaurant_review <- rbind(like_review, dislike_review)
restaurant_review %>% count(class)
view(restaurant_review)
# Acak data set biar ga beurutan
set.seed(10)
restaurant_review <- restaurant_review[sample(nrow(restaurant_review)), ]
# CLEANING DATASET
# Mengubah data reviewnya ke bentuk corpus
corpus <- Corpus(VectorSource(restaurant_review$text))
# Cleaning
corpus_clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
corpus[[15]]$content
corpus_clean[[15]]$content
# Mengubah corpus jadi dtm
dtm <- DocumentTermMatrix(corpus_clean)
# Partisi 3:1 data untuk test dan training
restaurant_review_train <- restaurant_review[1:1400,]
restaurant_review_test <- restaurant_review[1401:2000,]
corpus_clean_train <- corpus_clean[1:1400]
corpus_clean_test <- corpus_clean[1401:2000]
dtm_train <- dtm[1:1401,]
dtm_test <- dtm[1401:2000,]
dim(dtm_train)
dim(dtm_test)
# Feature Selection, ambil kata yang muncul minimal 10 kali
fiveFreq <- findFreqTerms(dtm_train, 10)
length(fiveFreq)
# set directory tempat simpan feature yg digunakan
# save featurenya
saveRDS(fiveFreq, "features.rds")
# Sesuaikan fitur pada data train dan test dengan fitur yang sudah diseleksi sebelumnya
dtm_train_nb <- corpus_clean_train %>%
DocumentTermMatrix(control=list(dictionary = fiveFreq))
dtm_test_nb <- corpus_clean_test %>%
DocumentTermMatrix(control=list(dictionary = fiveFreq))
dim(dtm_train_nb)
dim(dtm_test_nb)
# Funsi untuk convert jumlah kemunculan kata jadi yes (ada) dan no (ga ada)
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
# Apply the convert_count function to get final training and testing DTMs
trainNB <- apply(dtm_train_nb, 2, convert_count)
testNB <- apply(dtm_test_nb, 2, convert_count)
view(testNB)
# Membuat model naive bayes dari data training
classifier <- naiveBayes(trainNB, restaurant_review_train$class, laplace = 1)
# set directory tempat simpan model naivebayes nya
# save model untuk di gunakan pada aplikasi
save(classifier , file = 'NaiveBayesClassifier.rda')
# test model naivebayes nya
pred <- predict(classifier, newdata=testNB)
# Buat table hasil prediksi
table("Predictions"= pred,  "Actual" = restaurant_review_test$class)
# Confusion Matrix
conf_mat <- confusionMatrix(pred, restaurant_review_test$class)
conf_mat$overall['Accuracy']
View(df_restaurant)
library(RTextTools)
library(tm)
features <- readRDS("features.rds")
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
create_dtm <- function(data) {
corpus <- Corpus(VectorSource(data))
corpus_clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
create_dtm <- corpus_clean %>%
DocumentTermMatrix(control=list(dictionary = features))
}
extract_feature <- function(data) {
apply(create_dtm(data), 2, convert_count)
}
shiny::runApp()
install.packages("RTextTools")
library(rvest)
library(purrr)
library(textclean)
library(tokenizers)
library(wordcloud)
library(corpus)
library(dplyr)
library(tm)
baseUrl <- "https://www.tripadvisor.com"
restaurantUrl <- "/Restaurants-g294265-Singapore.html"
url <- paste(baseUrl, restaurantUrl, sep = "")
webpage <- read_html(url)
restaurantName <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_text()
restaurantReviewURL <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_attr('href')
dfrestaurant <- data.frame(name = restaurantName, link = restaurantReviewURL, stringsAsFactors = FALSE)
# set direktori untuk simpan data
setwd("C:/ALIVI/KULIAH/SEMESTER 6/TUGAS/Data Science/proyek")
# simpan data
saveRDS(dfrestaurant, "singapore.rds")
write.csv(dfrestaurant,"singapore.csv", row.names = FALSE)
dok<-read.csv("singapore.csv" , stringsAsFactors = TRUE)
corpusdok <- Corpus(VectorSource(dok$name))
inspect(corpusdok[1:10])
#Cleaning Hashtag
remove.hashtag <- function(x) gsub("#\\S+", "", x)
dok_hashtag <- tm_map(corpusdok, remove.hashtag)
inspect(dok_hashtag[1:10])
#Cleaning Punctuation
dok_punctuation<-tm_map(dok_hashtag,content_transformer(removePunctuation))
inspect(dok_punctuation[1:10])
#Cleaning Number
dok_nonumber<-tm_map(dok_punctuation, content_transformer(removeNumbers))
inspect(dok_nonumber[1:10])
df_restaurant=data.frame(name=unlist(sapply(dok_nonumber, `[`)),link = restaurantReviewURL, stringsAsFactors=F)
saveRDS(df_restaurant, "restaurant.rds")
# Cara ngambil semua review dari hotel pertama (diterapkan di shinynya)
dfrestaurant$name[1]
reviewUrl <- paste(baseUrl, dfrestaurant$link[1], sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.partial_entry') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- character()
reviewers <- character()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
while (!is.na(nextPage)) {
reviewUrl <- paste(baseUrl, nextPage, sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
}
p <- length(reviewers)
reviews <- reviews[1:p]
datareview <- data.frame(reviews, reviewers, stringsAsFactors = FALSE)
length(reviews)
View(reviews)
library(rvest)
baseUrl <- "https://www.tripadvisor.com"
get_restaurant_reviews <- function(restaurantUrl) {
withProgress(message = 'Scrape Tripadvisor', value = 0, {
reviewPage <- read_html(paste(baseUrl, restaurantUrl, sep = ""))
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- character()
reviewers <- character()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
while (!is.na(nextPage) & length(reviews) < 100) {
incProgress(1/100, detail = paste("jumlah review : ", length(reviews)))
reviewUrl <- paste(baseUrl, nextPage, sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
}
p <- length(reviewers)
reviews <- reviews[1:p]
data.frame(name =reviewers, Review = reviews, stringsAsFactors = FALSE)
})
}
library(tidyverse)
library(tm)
library(e1071)
library(caret)
library(dplyr)
# Load dataset
my_Dataset <- read.csv("Restaurant_Reviews.csv", stringsAsFactors = FALSE)
glimpse(my_Dataset)
# Ambil kolom reviewnya dan Liked (classnya)
restaurant_review <- my_Dataset %>%
select(text = Review, class = Liked)
restaurant_review$class <- as.factor(restaurant_review$class)
glimpse(restaurant_review)
# Ambil 1000 baris per class data untuk sample
like_review <- restaurant_review %>%
filter(class == "1")
dislike_review <- restaurant_review %>%
filter(class == "0")
restaurant_review <- rbind(like_review, dislike_review)
restaurant_review %>% count(class)
view(restaurant_review)
# Acak data set biar ga beurutan
set.seed(10)
restaurant_review <- restaurant_review[sample(nrow(restaurant_review)), ]
# CLEANING DATASET
# Mengubah data reviewnya ke bentuk corpus
corpus <- Corpus(VectorSource(restaurant_review$text))
# Cleaning
corpus_clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
corpus[[15]]$content
corpus_clean[[15]]$content
# Mengubah corpus jadi dtm
dtm <- DocumentTermMatrix(corpus_clean)
# Partisi 3:1 data untuk test dan training
restaurant_review_train <- restaurant_review[1:700,]
restaurant_review_test <- restaurant_review[701:1000,]
corpus_clean_train <- corpus_clean[1:700]
corpus_clean_test <- corpus_clean[701:1000]
dtm_train <- dtm[1:701,]
dtm_test <- dtm[701:1000,]
dim(dtm_train)
dim(dtm_test)
# Feature Selection, ambil kata yang muncul minimal 5 kali
fiveFreq <- findFreqTerms(dtm_train, 5)
length(fiveFreq)
# set directory tempat simpan feature yg digunakan
# save featurenya
saveRDS(fiveFreq, "features.rds")
# Sesuaikan fitur pada data train dan test dengan fitur yang sudah diseleksi sebelumnya
dtm_train_nb <- corpus_clean_train %>%
DocumentTermMatrix(control=list(dictionary = fiveFreq))
dtm_test_nb <- corpus_clean_test %>%
DocumentTermMatrix(control=list(dictionary = fiveFreq))
dim(dtm_train_nb)
dim(dtm_test_nb)
# Funsi untuk convert jumlah kemunculan kata jadi yes (ada) dan no (ga ada)
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
# Apply the convert_count function to get final training and testing DTMs
trainNB <- apply(dtm_train_nb, 2, convert_count)
testNB <- apply(dtm_test_nb, 2, convert_count)
view(testNB)
# Membuat model naive bayes dari data training
classifier <- naiveBayes(trainNB, restaurant_review_train$class, laplace = 1)
# set directory tempat simpan model naivebayes nya
# save model untuk di gunakan pada aplikasi
save(classifier , file = 'NaiveBayesClassifier.rda')
# test model naivebayes nya
pred <- predict(classifier, newdata=testNB)
# Buat table hasil prediksi
table("Predictions"= pred,  "Actual" = restaurant_review_test$class)
# Confusion Matrix
conf_mat <- confusionMatrix(pred, restaurant_review_test$class)
conf_mat$overall['Accuracy']
library(RTextTools)
library(tm)
features <- readRDS("features.rds")
convert_count <- function(x) {
y <- ifelse(x > 0, 1,0)
y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
y
}
create_dtm <- function(data) {
corpus <- Corpus(VectorSource(data))
corpus_clean <- corpus %>%
tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
create_dtm <- corpus_clean %>%
DocumentTermMatrix(control=list(dictionary = features))
}
extract_feature <- function(data) {
apply(create_dtm(data), 2, convert_count)
}
shiny::runApp()
install.packages("RTextTools")
View(dfrestaurant)
baseUrl <- "https://www.tripadvisor.com"
restaurantUrl <- "/Restaurants-g294265-Singapore.html"
url <- paste(baseUrl, restaurantUrl, sep = "")
webpage <- read_html(url)
restaurantName <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_text()
restaurantReviewURL <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_attr('href')
dfrestaurant <- data.frame(name = restaurantName, link = restaurantReviewURL, stringsAsFactors = FALSE)
View(dfrestaurant)
# set direktori untuk simpan data
setwd("C:/ALIVI/KULIAH/SEMESTER 6/TUGAS/Data Science/proyek")
# simpan data
saveRDS(dfrestaurant, "singapore.rds")
write.csv(dfrestaurant,"singapore.csv", row.names = FALSE)
dok<-read.csv("singapore.csv" , stringsAsFactors = TRUE)
corpusdok <- Corpus(VectorSource(dok$name))
inspect(corpusdok[1:10])
#Cleaning Hashtag
remove.hashtag <- function(x) gsub("#\\S+", "", x)
dok_hashtag <- tm_map(corpusdok, remove.hashtag)
inspect(dok_hashtag[1:10])
#Cleaning Punctuation
dok_punctuation<-tm_map(dok_hashtag,content_transformer(removePunctuation))
inspect(dok_punctuation[1:10])
#Cleaning Number
dok_nonumber<-tm_map(dok_punctuation, content_transformer(removeNumbers))
inspect(dok_nonumber[1:10])
df_restaurant=data.frame(name=unlist(sapply(dok_nonumber, `[`)),link = restaurantReviewURL, stringsAsFactors=F)
saveRDS(df_restaurant, "restaurant.rds")
View(df_restaurant)
View(datareviews)
View(datareview)
View(df_restaurant)
View(dislike_review)
R.version.strig
R.version.string
library(rvest)
library(purrr)
library(textclean)
library(tokenizers)
library(wordcloud)
library(corpus)
library(dplyr)
library(tm)
baseUrl <- "https://www.tripadvisor.com"
restaurantUrl <- "/Restaurants-g294265-Singapore.html"
url <- paste(baseUrl, restaurantUrl, sep = "")
webpage <- read_html(url)
restaurantName <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_text()
restaurantReviewURL <- webpage %>% html_nodes('[class="_15_ydu6b"]') %>% html_attr('href')
dfrestaurant <- data.frame(name = restaurantName, link = restaurantReviewURL, stringsAsFactors = FALSE)
View(dfrestaurant)
# set direktori untuk simpan data
setwd("C:/ALIVI/KULIAH/SEMESTER 6/TUGAS/Data Science/proyek")
# simpan data
saveRDS(dfrestaurant, "singapore.rds")
write.csv(dfrestaurant,"singapore.csv", row.names = FALSE)
dok<-read.csv("singapore.csv" , stringsAsFactors = TRUE)
corpusdok <- Corpus(VectorSource(dok$name))
inspect(corpusdok[1:10])
#Cleaning Hashtag
remove.hashtag <- function(x) gsub("#\\S+", "", x)
dok_hashtag <- tm_map(corpusdok, remove.hashtag)
inspect(dok_hashtag[1:10])
#Cleaning Punctuation
dok_punctuation<-tm_map(dok_hashtag,content_transformer(removePunctuation))
inspect(dok_punctuation[1:10])
#Cleaning Number
dok_nonumber<-tm_map(dok_punctuation, content_transformer(removeNumbers))
inspect(dok_nonumber[1:10])
df_restaurant=data.frame(name=unlist(sapply(dok_nonumber, `[`)),link = restaurantReviewURL, stringsAsFactors=F)
saveRDS(df_restaurant, "restaurant.rds")
View(df_restaurant)
# Cara ngambil semua review dari hotel pertama (diterapkan di shinynya)
dfrestaurant$name[1]
reviewUrl <- paste(baseUrl, dfrestaurant$link[1], sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.partial_entry') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- character()
reviewers <- character()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
while (!is.na(nextPage)) {
reviewUrl <- paste(baseUrl, nextPage, sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
}
p <- length(reviewers)
reviews <- reviews[1:p]
datareview <- data.frame(reviews, reviewers, stringsAsFactors = FALSE)
length(reviews)
View(datareview)
a<-read.csv("reviews_restaurant", stringsAsFactors = TRUE)
View(restaurant_review)
load("C:/ALIVI/KULIAH/SEMESTER 6/TUGAS/Data Science/proyek/reviews_restaurant.csv")
dok<-read.csv("Restaurant_Reviews.csv" , stringsAsFactors = TRUE)
write.csv(dftraining,"Restaurant_Reviews.csv", row.names = FALSE)
length(reviews)
View(datareview)
View(datareview)
View(datareview)
View(df_restaurant)
View(df_restaurant)
View(dfrestaurant)
View(dfrestaurant)
View(dislike_review)
View(dislike_review)
View(dok)
View(dok)
View(dok_hashtag)
View(dok_hashtag)
View(reviewPage)
View(reviewPage)
View(testNB)
View(testNB)
library(rvest)
baseUrl <- "https://www.tripadvisor.com"
get_restaurant_reviews <- function(restaurantUrl) {
withProgress(message = 'Scrape Tripadvisor', value = 0, {
reviewPage <- read_html(paste(baseUrl, restaurantUrl, sep = ""))
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- character()
reviewers <- character()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
while (!is.na(nextPage) & length(reviews) < 100) {
incProgress(1/100, detail = paste("jumlah review : ", length(reviews)))
reviewUrl <- paste(baseUrl, nextPage, sep = "")
reviewPage <- read_html(reviewUrl)
review <- reviewPage %>%
html_nodes('.prw_rup.prw_reviews_text_summary_hsx') %>%
html_text()
reviewer <- reviewPage %>%
html_nodes('.info_text.pointer_cursor') %>%
html_text()
reviews <- c(reviews, review)
reviewers <- c(reviewers, reviewer)
nextPage <- reviewPage %>%
html_nodes('.next') %>%
html_attr('href')
}
p <- length(reviewers)
reviews <- reviews[1:p]
data.frame(name =reviewers, Review = reviews, stringsAsFactors = FALSE)
})
}
View(View)
View(review)
View(df_restaurant)
View(dfrestaurant)
View(dislike_review)
View(restaurant_review)
View(restaurant_review)
View(restaurant_review_train)
View(restaurant_review_train)
View(testNB)
View(testNB)
View(my_Dataset)
View(my_Dataset)
View(my_Dataset)
View(restaurant_review)
View(restaurant_review)
View(restaurant_review_test)
View(restaurant_review_train)
View(restaurant_review_train)
View(testNB)
View(testNB)
View(datareview)
View(datareview)
